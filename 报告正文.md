# 航空公司客户流失分析
## 一、研究背景
随着互联网和移动网络的高速发展，一个全新的网络经济时代已经到来。生产力的迅速发展已经使得大多数企业的产品质量在行业中基本趋同，而且价格也相差无几。在价格与质量都拉不开差距的情况下，客户忠诚就显得尤为重要。然而，很多的企业都在做着“一锤子买卖”，在产品投放市场初期注重吸引客户，却在后期客户维护上不愿意下功夫，使得客户变成了“一次性客户”。在一些产品与服务区分度不大的行业中，如果不注重老客户的维系，那么客户流失乃至流向竞争企业便会成为公司常态。通常而言，锁定比吸引更重要。锁定所带来的不仅仅是客户的保留，客户的忠诚更表明客户对企业及其产品满意度较高。而当客户将自己的“满意”传达给周围其他人时，这种“宣传”的效果胜过企业花巨资拍摄的广告的10倍。据统计，吸引一个新客户需要花费的成本是保留一个老客户所需成本的5～10倍。

客户留存是以研究新用户为目标对象的，即研究某一个时间点的一批用户在随后的几天、几周、几个月的时间内的生命周期情况，从宏观上把握用户的生命周期长度以及应用可以改善的余地。通常来讲，用户在某段时间内开始使用应用，经过一段时间后，仍然继续使用该应用的用户，被认作是留存用户。这部分用户占当时新增用户的比例即是留存率，会按照每隔1单位时间（例日、周、月）来进行统计。留存用户和留存率体现了应用的质量和保留用户的能力。留存率反映的实际上是一种转化率，即由初期的不稳定的用户转化为活跃用户、稳定用户、忠诚用户的过程。


## 二、定义挖掘目标
1. 定义客户流失

我们以第二年飞行次数与第一年飞行次数的比例来定义客户流失的类别：

| 客户类型 | 定义 |
|------|---|
| 已流失客户 | 第二年飞行次数与第一年飞行次数比例小于50% |
| 准流失客户 | 第二年飞行次数与第一年飞行次数比例介于50%到90%之间 |
| 未流失客户 | 第二年飞行次数与第一年飞行次数比例大于90% |

2. 定义挖掘目标

在现有数据与客户流失分类标准的框架下，通过选取相关性较高的属性，构建客户的流失模型，运用模型预测未来客户的类别归属（未流失、准流失或已流失）

## 三、数据探索
```python
# 导入所需要的包
import numpy as np
import pandas as pd
import scipy
import matplotlib.pyplot as plt
import seaborn as sns

# 使用read_csv()函数把“air_data.csv”读入当前工作空间
data=pd.read_csv('./air_data.csv',encoding='UTF-8')
print(data)
```
#### 数据质量分析
- 缺失值
```python
# 表中各属性值缺失情况概览
data.isnull().sum()
```
```python
MEMBER_NO                     0
FFP_DATE                      0
FIRST_FLIGHT_DATE             0
GENDER                        3
FFP_TIER                      0
WORK_CITY                  2269
WORK_PROVINCE              3248
WORK_COUNTRY                 26
AGE                         420
LOAD_TIME                     0
FLIGHT_COUNT                  0
BP_SUM                        0
EP_SUM_YR_1                   0
EP_SUM_YR_2                   0
SUM_YR_1                    551
SUM_YR_2                    138
SEG_KM_SUM                    0
WEIGHTED_SEG_KM               0
LAST_FLIGHT_DATE              0
AVG_FLIGHT_COUNT              0
AVG_BP_SUM                    0
BEGIN_TO_FIRST                0
LAST_TO_END                   0
AVG_INTERVAL                  0
MAX_INTERVAL                  0
ADD_POINTS_SUM_YR_1           0
ADD_POINTS_SUM_YR_2           0
EXCHANGE_COUNT                0
avg_discount                  0
P1Y_Flight_Count              0
L1Y_Flight_Count              0
P1Y_BP_SUM                    0
L1Y_BP_SUM                    0
EP_SUM                        0
ADD_Point_SUM                 0
Eli_Add_Point_Sum             0
L1Y_ELi_Add_Points            0
Points_Sum                    0
L1Y_Points_Sum                0
Ration_L1Y_Flight_Count       0
Ration_P1Y_Flight_Count       0
Ration_P1Y_BPS                0
Ration_L1Y_BPS                0
Point_NotFlight               0
dtype: int64
```
由结果可以看出，在工作城市、省份、国家及年龄、第一年/第二年总票价等属性上数据是有缺失的。对数据缺失数量做一个简单的可视化分析：
```python
# 缺失值统计柱形图
nan = pd.DataFrame(data.isnull().sum())
nan.plot(kind = 'bar')
plt.show()
```
![缺失值统计图](https://github.com/dopamineV/data-analysis/blob/master/%E7%BC%BA%E5%A4%B1%E5%80%BC.png)

由数据及图可知，用户的工作地点信息缺失较多，但由于不便度量用户的飞行距离（短距离高票价的用户是航空公司应着力维护的），因此工作地点相关属性将不被纳入模型构建过程中，因此不予处理。用户年龄仅用于分析用户年龄分布，对模型构建没有太大价值，因而同样不予处理。而对于第一年、第二年的总票价，因其直接关系到客户单次飞行平均票价（客单价），因而对这部分缺失数据做删除处理，处理步骤见后文数据预处理部分。

- 异常值
```python
# 飞行次数与总基本积分关系的散点图
FLIGHT_COUNT = pd.DataFrame(data['FLIGHT_COUNT'])
BP_SUM = pd.DataFrame(data['BP_SUM'])

plt.plot(FLIGHT_COUNT,BP_SUM,'o')
plt.show()
```
![异常值统计图1](https://github.com/dopamineV/data-analysis/blob/master/%E6%95%A3%E7%82%B9%E5%9B%BE.png)

```python
# 用箱线图表现年龄分布，寻找异常值
fig,axes = plt.subplots()
data['AGE'][data.AGE < 120].plot(kind='box',ax=axes)
axes.set_ylabel('values of age')
plt.show()
```
![异常值统计图2](https://github.com/dopamineV/data-analysis/blob/master/%E7%AE%B1%E7%BA%BF%E5%9B%BE.png)
- 重复值
```python
# 以用户ID检测数据中是否有重复值
data.drop_duplicates(['MEMBER_NO'])
data['MEMBER_NO'].count()
```
由计数结果知用户ID为唯一标识且无重复数据，因而无需进行重复数据的清洗及保证数据一致性的相关处理

2. 数据特征分析
分布、对比、统计量、贡献度、相关性

## 四、数据预处理
数据清洗：重复、噪声、缺失、异常
缺失：
数据集成：冗余/不同源数据间矛盾
数据变换：正态、规范化、连续属性离散化、属性构造（客户价值）
数据规约：属性规约、数值规约

## 五、挖掘建模
分类与预测：决策树or随机森林
1. 划分训练集
2. 模型训练

## 六、模型评价
ROC曲线、准确率、正确率、召回率

## 七、分析结论
